#!/usr/bin/env python3
"""
Vision Scores Analysis example demonstrating the Tahoe Agent with LangChain native tools.

This example shows:
1. Vision scores analysis with different LLM providers
2. Native LangChain tool integration
3. Static DAG workflow (prompt -> tool_calling -> retrieval)
4. Configurable path management (NEW)

Usage:
    python example.py vision-scores --data-path /Users/gpalla/Datasets/tahoe --cell-name HS-578T
    python example.py vision-scores --provider anthropic --model claude-3-5-sonnet-20241022
    python example.py vision-scores --provider lambda --model hermes-3-llama-3.1-405b-fp8
    python example.py models
    python example.py paths  # NEW: Show path configuration
"""

from typing import Optional, Dict

import typer
from typing_extensions import Annotated

from tahoe_agent import BaseAgent
from tahoe_agent.paths import configure_paths, get_paths  # NEW
from tahoe_agent.llm import SourceType
from tahoe_agent.logging_config import get_logger

logger = get_logger()


app = typer.Typer(
    help="Tahoe Agent Vision Scores Demo - Analyze vision scores with different AI providers"
)


@app.command()
def signature_analysis(
    analysis_type: Annotated[
        str, typer.Option(help="Type of analysis to run: 'vision' or 'gsea'")
    ] = "vision",
    cell_name: Annotated[
        Optional[str], typer.Option(help="Cell name to analyze")
    ] = None,
    drug_name: Annotated[str, typer.Option(help="Drug name to analyze")] = "Adagrasib",
    provider: Annotated[str, typer.Option(help="AI provider")] = "lambda",
    model: Annotated[
        Optional[str], typer.Option(help="Model name")
    ] = "hermes-3-llama-3.1-405b-fp8",
    custom_data_dir: Annotated[
        Optional[str], typer.Option(help="Custom data directory")
    ] = None,
    custom_results_dir: Annotated[
        Optional[str], typer.Option(help="Custom results directory")
    ] = None,
) -> None:
    """Signature analysis demonstration."""
    if custom_data_dir or custom_results_dir:
        logger.info("[signature_analysis] ğŸ”§ Configuring custom paths...")
        config_kwargs = {}
        if custom_data_dir:
            config_kwargs["data_dir"] = custom_data_dir
        if custom_results_dir:
            config_kwargs["results_dir"] = custom_results_dir
        configure_paths(**config_kwargs)

        paths = get_paths()
        logger.info(f"[signature_analysis]   Data directory: {paths.data_dir}")
        logger.info(f"[signature_analysis]   Results directory: {paths.results_dir}")

    if model is None:
        if provider == "openai":
            model = "gpt-4o-mini"
        elif provider == "anthropic":
            model = "claude-3-5-sonnet-20241022"
        elif provider == "lambda":
            model = "hermes-3-llama-3.1-405b-fp8"
        else:
            logger.error(f"[signature_analysis] Unknown provider: {provider}")
            raise typer.Exit(1)

    source_map: Dict[str, SourceType] = {
        "openai": "OpenAI",
        "anthropic": "Anthropic",
        "lambda": "Lambda",
    }
    source = source_map.get(provider)

    logger.info(
        f"[signature_analysis] ğŸ”¬ Signature Analysis Demo - {provider.title()} ({model})"
    )
    logger.info("[signature_analysis] " + "=" * 50)

    try:
        agent = BaseAgent(
            llm=model,
            source=source,
            temperature=0.7,
            tool_config={"drug_name": drug_name},
        )

        logger.info(
            f"[signature_analysis] ğŸ“Š Analyzing signatures for drug: {drug_name}"
        )
        if cell_name:
            logger.info(f"[signature_analysis] ğŸ§¬ Cell: {cell_name}")

        if analysis_type == "vision":
            prompt = f"Use the analyze_vision_scores tool to analyze the vision scores for drug '{drug_name}'"
            if cell_name:
                prompt += f" in cell line '{cell_name}'"
            prompt += (
                ". Show me the top features and provide insights about the results."
            )
        elif analysis_type == "gsea":
            prompt = f"Use the analyze_gsea_scores tool to analyze the GSEA scores for drug '{drug_name}'"
            if cell_name:
                prompt += f" in cell line '{cell_name}'"
            prompt += (
                ". Show me the top enrichments and provide insights about the results."
            )
        else:
            logger.error(
                f"[signature_analysis] âŒ Invalid analysis type: {analysis_type}"
            )
            raise typer.Exit(1)

        logger.info(f"[signature_analysis] \nğŸ¤– Sending prompt: {prompt}")

        log, response, _, _ = agent.run(prompt)

        logger.info("[signature_analysis] \nğŸ“ Full execution log:")
        for i, (role, content) in enumerate(log):
            logger.info(
                f"[signature_analysis]   {i+1}. [{role}]: {content[:200]}{'...' if len(content) > 200 else ''}"
            )

        logger.info(f"[signature_analysis] \nğŸ¯ Final Agent Response: {response}")

    except Exception as e:
        logger.error(f"[signature_analysis] âŒ Signature analysis demo failed: {e}")
        raise typer.Exit(1)


@app.command()
def drug_ranking(
    analysis_type: Annotated[
        str, typer.Option(help="Type of analysis to run: 'vision' or 'gsea'")
    ] = "vision",
    cell_name: Annotated[
        Optional[str], typer.Option(help="Cell name to analyze")
    ] = None,
    drug_name: Annotated[str, typer.Option(help="Drug name to analyze")] = "Adagrasib",
    provider: Annotated[str, typer.Option(help="AI provider")] = "lambda",
    model: Annotated[
        Optional[str], typer.Option(help="Model name")
    ] = "llama-4-maverick-17b-128e-instruct-fp8",  # "hermes-3-llama-3.1-405b-fp8", #"deepseek-r1-671b",  #
    # NEW: Path configuration options
    custom_data_dir: Annotated[
        Optional[str], typer.Option(help="Custom data directory")
    ] = None,
    custom_results_dir: Annotated[
        Optional[str], typer.Option(help="Custom results directory")
    ] = None,
) -> None:
    """Test drug ranking functionality."""

    # NEW: Configure custom paths if provided
    if custom_data_dir or custom_results_dir:
        logger.info("[drug_ranking] ğŸ”§ Configuring custom paths...")
        config_kwargs = {}
        if custom_data_dir:
            config_kwargs["data_dir"] = custom_data_dir
        if custom_results_dir:
            config_kwargs["results_dir"] = custom_results_dir
        configure_paths(**config_kwargs)
        logger.info(f"[drug_ranking]   Data directory: {get_paths().data_dir}")
        logger.info(f"[drug_ranking]   Results directory: {get_paths().results_dir}")

    # Set defaults based on provider
    if model is None:
        if provider == "openai":
            model = "gpt-4o-mini"
        elif provider == "anthropic":
            model = "claude-3-5-sonnet-20241022"
        elif provider == "lambda":
            model = "hermes-3-llama-3.1-405b-fp8"
        else:
            logger.error(f"[drug_ranking] Unknown provider: {provider}")
            raise typer.Exit(1)

    source_map: Dict[str, SourceType] = {
        "openai": "OpenAI",
        "anthropic": "Anthropic",
        "lambda": "Lambda",
    }
    source = source_map.get(provider)

    logger.info(f"[drug_ranking] ğŸ’Š Drug Ranking Demo - {provider.title()} ({model})")
    logger.info("[drug_ranking] " + "=" * 50)

    try:
        # Initialize agent with hidden drug configuration
        agent = BaseAgent(
            llm=model,
            source=source,
            temperature=0.7,
            tool_config={"drug_name": drug_name},  # Hidden from LLM
        )

        # Build prompt based on whether cell_name is provided
        if analysis_type == "vision":
            base_prompt = (
                "Use the analyze_vision_scores tool to analyze the vision scores"
            )
            if cell_name:
                base_prompt += f" for cell line '{cell_name}'"
            prompt = f"""{base_prompt}.

            Show me the top features and provide insights about the results.

            After the analysis, when the summary is available, rank drugs based on how well their mechanisms of action match the observed biological signatures.
            """
        elif analysis_type == "gsea":
            base_prompt = "Use the analyze_gsea_scores tool to analyze the GSEA scores"
            if cell_name:
                base_prompt += f" for cell line '{cell_name}'"
            prompt = f"""{base_prompt}.

            Show me the top enrichments and provide insights about the results.

            After the analysis, when the summary is available, rank drugs based on how well their mechanisms of action match the observed biological signatures.
            """
        else:
            logger.error(f"[drug_ranking] âŒ Invalid analysis type: {analysis_type}")
            raise typer.Exit(1)

        logger.info(
            "[drug_ranking] ğŸ’¬ Testing drug ranking with BLIND prompt (drug name hidden):"
        )
        logger.info(f"[drug_ranking]    Hidden drug: {drug_name}")
        logger.info(f"[drug_ranking]    Prompt: {prompt[:100]}...")
        logger.info("[drug_ranking] \nğŸ¤– Running agent workflow...")

        log, response, structured_rankings, summary = agent.run(prompt)

        # Show execution log
        logger.info("[drug_ranking] \nğŸ“ Execution log:")
        for i, (role, content) in enumerate(log):
            logger.info(
                f"[drug_ranking]   {i+1}. [{role}]: {content[:150]}{'...' if len(content) > 150 else ''}"
            )

        logger.info(
            f"[drug_ranking] \nğŸ¯ Final Drug Rankings (Hidden drug was: {drug_name}):"
        )
        logger.info("[drug_ranking] " + "=" * 50)
        logger.info(f"[drug_ranking] {response}")

    except Exception as e:
        logger.error(f"[drug_ranking] âŒ Drug ranking demo failed: {e}")
        raise typer.Exit(1)


if __name__ == "__main__":
    app()
